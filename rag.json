{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333e4fb-6dd4-478f-89b3-5eee81d6a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Initializing RAG System\n",
      "============================================================\n",
      "✓ Ollama client initialized with model: deepseek-r1:1.5b\n",
      "ChromaDB initialized with collection: my_documents\n",
      "Current document count: 0\n",
      "✓ ChromaDB initialized\n",
      "\n",
      "STEP 1: Adding PDF to RAG System\n",
      "============================================================\n",
      "Processing PDF: C:\\Users\\kbino\\OneDrive\\Desktop\\RAG_pdf.pdf\n",
      "------------------------------------------------------------\n",
      "Total pages: 15\n",
      "Extracted 39936 characters from PDF\n",
      "Created 13 text chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbino\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz:  15%|▊    | 12.1M/79.3M [00:06<00:21, 3.26MiB/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RAG Application with ChromaDB and Local Ollama DeepSeek-R1:1.5b\n",
    "Step-by-step implementation for question answering with PDF documents\n",
    "\"\"\"\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import PyPDF2\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Setup Ollama Client for DeepSeek\n",
    "# ============================================================================\n",
    "\n",
    "class OllamaClient:\n",
    "    \"\"\"Client to interact with local Ollama API\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"deepseek-r1:1.5b\", base_url: str = \"http://localhost:11434\"):\n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url\n",
    "        self.api_url = f\"{base_url}/api/generate\"\n",
    "    \n",
    "    def generate(self, prompt: str, stream: bool = False) -> str:\n",
    "        \"\"\"Generate response from Ollama model\"\"\"\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": stream\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.api_url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            if stream:\n",
    "                # Handle streaming response\n",
    "                full_response = \"\"\n",
    "                for line in response.iter_lines():\n",
    "                    if line:\n",
    "                        json_response = json.loads(line)\n",
    "                        full_response += json_response.get(\"response\", \"\")\n",
    "                return full_response\n",
    "            else:\n",
    "                # Handle non-streaming response\n",
    "                result = response.json()\n",
    "                return result.get(\"response\", \"\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return f\"Error connecting to Ollama: {e}\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: PDF Processing Functions\n",
    "# ============================================================================\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text content from a PDF file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            print(f\"Total pages: {len(pdf_reader.pages)}\")\n",
    "            \n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                page_text = page.extract_text()\n",
    "                text += page_text\n",
    "                text += f\"\\n\\n--- End of Page {page_num + 1} ---\\n\\n\"\n",
    "                \n",
    "        print(f\"Extracted {len(text)} characters from PDF\")\n",
    "        return text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"Split text into overlapping chunks for better context\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk.strip():\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    print(f\"Created {len(chunks)} text chunks\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: ChromaDB Vector Database Setup\n",
    "# ============================================================================\n",
    "\n",
    "class ChromaDBManager:\n",
    "    \"\"\"Manage ChromaDB vector database operations\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"rag_documents\", persist_directory: str = \"./chroma_db\"):\n",
    "        \"\"\"Initialize ChromaDB with persistent storage\"\"\"\n",
    "        \n",
    "        # Create persistent client\n",
    "        self.client = chromadb.PersistentClient(path=persist_directory)\n",
    "        \n",
    "        # Use default embedding function (all-MiniLM-L6-v2)\n",
    "        self.embedding_function = embedding_functions.DefaultEmbeddingFunction()\n",
    "        \n",
    "        # Create or get collection\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=self.embedding_function,\n",
    "            metadata={\"description\": \"RAG document collection\"}\n",
    "        )\n",
    "        \n",
    "        print(f\"ChromaDB initialized with collection: {collection_name}\")\n",
    "        print(f\"Current document count: {self.collection.count()}\")\n",
    "    \n",
    "    def add_documents(self, chunks: List[str], source: str):\n",
    "        \"\"\"Add document chunks to ChromaDB\"\"\"\n",
    "        if not chunks:\n",
    "            print(\"No chunks to add\")\n",
    "            return\n",
    "        \n",
    "        # Create unique IDs for each chunk\n",
    "        ids = [f\"{source}_chunk_{i}\" for i in range(len(chunks))]\n",
    "        \n",
    "        # Create metadata for each chunk\n",
    "        metadatas = [\n",
    "            {\n",
    "                \"source\": source,\n",
    "                \"chunk_id\": i,\n",
    "                \"total_chunks\": len(chunks)\n",
    "            } \n",
    "            for i in range(len(chunks))\n",
    "        ]\n",
    "        \n",
    "        # Add to collection\n",
    "        self.collection.add(\n",
    "            documents=chunks,\n",
    "            ids=ids,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        print(f\"Added {len(chunks)} chunks to database\")\n",
    "        print(f\"Total documents in database: {self.collection.count()}\")\n",
    "    \n",
    "    def query(self, query_text: str, n_results: int = 3) -> Dict:\n",
    "        \"\"\"Query the database for relevant chunks\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def clear_collection(self):\n",
    "        \"\"\"Clear all documents from collection\"\"\"\n",
    "        self.client.delete_collection(name=self.collection.name)\n",
    "        print(\"Collection cleared\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: RAG System - Combining Everything\n",
    "# ============================================================================\n",
    "\n",
    "class RAGSystem:\n",
    "    \"\"\"Complete RAG system with ChromaDB and Ollama DeepSeek\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name: str = \"deepseek-r1:1.5b\",\n",
    "                 collection_name: str = \"rag_documents\"):\n",
    "        \"\"\"Initialize RAG system\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Initializing RAG System\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Initialize Ollama client\n",
    "        self.ollama = OllamaClient(model_name=model_name)\n",
    "        print(f\"✓ Ollama client initialized with model: {model_name}\")\n",
    "        \n",
    "        # Initialize ChromaDB\n",
    "        self.db = ChromaDBManager(collection_name=collection_name)\n",
    "        print(f\"✓ ChromaDB initialized\")\n",
    "        print()\n",
    "    \n",
    "    def add_pdf(self, pdf_path: str, chunk_size: int = 500):\n",
    "        \"\"\"Add PDF document to the RAG system\"\"\"\n",
    "        print(f\"Processing PDF: {pdf_path}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Step 1: Extract text\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        if not text:\n",
    "            print(\"Failed to extract text from PDF\")\n",
    "            return False\n",
    "        \n",
    "        # Step 2: Chunk text\n",
    "        chunks = chunk_text(text, chunk_size=chunk_size)\n",
    "        \n",
    "        # Step 3: Add to database\n",
    "        source_name = os.path.basename(pdf_path)\n",
    "        self.db.add_documents(chunks, source=source_name)\n",
    "        \n",
    "        print(\"✓ PDF successfully added to RAG system\")\n",
    "        print()\n",
    "        return True\n",
    "    \n",
    "    def ask(self, question: str, n_results: int = 3, verbose: bool = True) -> str:\n",
    "        \"\"\"Ask a question using RAG\"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Question: {question}\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Retrieve relevant chunks from ChromaDB\n",
    "        if verbose:\n",
    "            print(\"Searching database for relevant context...\")\n",
    "        \n",
    "        results = self.db.query(question, n_results=n_results)\n",
    "        \n",
    "        if not results['documents'][0]:\n",
    "            return \"No relevant information found in the database.\"\n",
    "        \n",
    "        # Step 2: Prepare context from retrieved chunks\n",
    "        context = \"\\n\\n\".join(results['documents'][0])\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ Retrieved {len(results['documents'][0])} relevant chunks\")\n",
    "            print()\n",
    "        \n",
    "        # Step 3: Create prompt for DeepSeek\n",
    "        prompt = f\"\"\"You are a helpful assistant. Answer the question based ONLY on the following context.\n",
    "If the answer cannot be found in the context, say \"I cannot answer this based on the provided context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        # Step 4: Generate answer using DeepSeek\n",
    "        if verbose:\n",
    "            print(\"Generating answer with DeepSeek-R1...\")\n",
    "            print()\n",
    "        \n",
    "        answer = self.ollama.generate(prompt)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"Answer:\")\n",
    "            print(\"=\" * 60)\n",
    "            print(answer)\n",
    "            print()\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get database statistics\"\"\"\n",
    "        count = self.db.collection.count()\n",
    "        print(f\"Total documents in database: {count}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Main Usage Example\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function demonstrating the RAG system\"\"\"\n",
    "    \n",
    "    # Initialize RAG system\n",
    "    rag = RAGSystem(\n",
    "        model_name=\"deepseek-r1:1.5b\",\n",
    "        collection_name=\"my_documents\"\n",
    "    )\n",
    "    \n",
    "    # Example: Add a PDF document\n",
    "    pdf_file = r\"C:\\Users\\kbino\\OneDrive\\Desktop\\RAG_pdf.pdf\" # Replace with your PDF file\n",
    "    \n",
    "    if os.path.exists(pdf_file):\n",
    "        print(\"STEP 1: Adding PDF to RAG System\")\n",
    "        print(\"=\" * 60)\n",
    "        rag.add_pdf(pdf_file, chunk_size=500)\n",
    "        \n",
    "        # Get statistics\n",
    "        rag.get_stats()\n",
    "        print()\n",
    "        \n",
    "        # Example questions\n",
    "        questions = [\n",
    "            \"What is the main topic of this document?\",\n",
    "            \"Summarize the key points\",\n",
    "            \"What are the important findings?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"STEP 2: Asking Questions\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"\\n--- Question {i} ---\")\n",
    "            answer = rag.ask(question, n_results=3)\n",
    "            print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"❌ PDF file '{pdf_file}' not found!\")\n",
    "        print(\"\\nTo use this RAG system:\")\n",
    "        print(\"1. Install requirements: pip install chromadb pypdf2 requests\")\n",
    "        print(\"2. Make sure Ollama is running: ollama serve\")\n",
    "        print(\"3. Pull DeepSeek model: ollama pull deepseek-r1:1.5b\")\n",
    "        print(\"4. Place a PDF file and update the pdf_file variable\")\n",
    "        print(\"5. Run this script: python rag_system.py\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Run the application\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2616c93-e0bc-4a12-9f24-04ef823bf0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
